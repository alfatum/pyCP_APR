
<!DOCTYPE html>

<html lang="Python">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pyCP_APR.torch_backend package &#8212; pyCP_APR 1.0.1 documentation</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="pyCP_APR.numpy_backend package" href="pyCP_APR.numpy_backend.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="Python">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">pyCP_APR 1.0.1 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="CP_APR.html">
   pyCP_APR.CP_APR API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="datasets.html">
   pyCP_APR.datasets API
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="modules.html">
   pyCP_APR Package
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="pyCP_APR.html">
     pyCP_APR package
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="pyCP_APR.applications.html">
       pyCP_APR.applications package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pyCP_APR.numpy_backend.html">
       pyCP_APR.numpy_backend package
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       pyCP_APR.torch_backend package
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/pyCP_APR.torch_backend.rst.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.rst</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#submodules">
   Submodules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.CP_APR_Torch">
   pyCP_APR.torch_backend.CP_APR_Torch module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.ktensor_Torch">
   pyCP_APR.torch_backend.ktensor_Torch module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.sptensor_Torch">
   pyCP_APR.torch_backend.sptensor_Torch module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend">
   Module contents
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="pycp-apr-torch-backend-package">
<h1>pyCP_APR.torch_backend package<a class="headerlink" href="#pycp-apr-torch-backend-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-pyCP_APR.torch_backend.CP_APR_Torch">
<span id="pycp-apr-torch-backend-cp-apr-torch-module"></span><h2>pyCP_APR.torch_backend.CP_APR_Torch module<a class="headerlink" href="#module-pyCP_APR.torch_backend.CP_APR_Torch" title="Permalink to this headline">¶</a></h2>
<p>Python implementation of the CP-APR algorithm [1-4] with PyTorch backend.</p>
<p>This backend can be used to factorize sparse tensorsin COO format on GPU or CPU.</p>
<p class="rubric">References</p>
<p>[1] General software, latest release: Brett W. Bader, Tamara G. Kolda and others, Tensor Toolbox for MATLAB, Version 3.2.1, www.tensortoolbox.org, April 5, 2021.</p>
<p>[2] Dense tensors: B. W. Bader and T. G. Kolda, Algorithm 862: MATLAB Tensor Classes for Fast Algorithm Prototyping, ACM Trans. Mathematical Software, 32(4):635-653, 2006, <a class="reference external" href="http://dx.doi.org/10.1145/1186785.1186794">http://dx.doi.org/10.1145/1186785.1186794</a>.</p>
<p>[3] Sparse, Kruskal, and Tucker tensors: B. W. Bader and T. G. Kolda, Efficient MATLAB Computations with Sparse and Factored Tensors, SIAM J. Scientific Computing, 30(1):205-231, 2007, <a class="reference external" href="http://dx.doi.org/10.1137/060676489">http://dx.doi.org/10.1137/060676489</a>.</p>
<p>[4] Chi, E.C. and Kolda, T.G., 2012. On tensors, sparsity, and nonnegative factorizations. SIAM Journal on Matrix Analysis and Applications, 33(4), pp.1272-1299.</p>
<p>&#64;author: Maksim Ekin Eren</p>
<dl class="py class">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyCP_APR.torch_backend.CP_APR_Torch.</span></span><span class="sig-name descname"><span class="pre">CP_APR_MU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kappa</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kappa_tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_inner_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_inner_itn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">simple_verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stoptime</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'0'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'numpy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'torch.DoubleTensor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">follow_M</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/CP_APR_Torch.html#CP_APR_MU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Initilize the CP_APR_MU class. Sets up the class variables and the CUDA for
tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) -- Prevents zero division. Default is 1e-10.</p></li>
<li><p><strong>kappa</strong> (<em>float</em><em>, </em><em>optional</em>) -- Fix slackness level. Default is 1e-2.</p></li>
<li><p><strong>kappa_tol</strong> (<em>float</em><em>, </em><em>optional</em>) -- Tolerance on slackness level. Default is 1e-10.</p></li>
<li><p><strong>max_inner_iters</strong> (<em>int</em><em>, </em><em>optional</em>) -- Number of inner iterations per epoch. Default is 10.</p></li>
<li><p><strong>n_iters</strong> (<em>int</em><em>, </em><em>optional</em>) -- Number of iterations during optimization or epoch. Default is 1000.</p></li>
<li><p><strong>print_inner_itn</strong> (<em>int</em><em>, </em><em>optional</em>) -- Print every <em>n</em> inner iterations. Does not print if 0. Default is 0.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>optional</em>) -- Print every n epoch, or <code class="docutils literal notranslate"><span class="pre">n_iters</span></code>. Does not print if 0. Default is 10.</p></li>
<li><p><strong>simple_verbose</strong> (<em>bool</em><em>, </em><em>optional</em>) -- Turns off details for verbose, such as fit, but instead shows a progress bar.</p></li>
<li><p><strong>stoptime</strong> (<em>float</em><em>, </em><em>optional</em>) -- Number of seconds before early stopping. Default is 1e6.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) -- KKT violations tolerance. Default is 1e-4.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>optional</em>) -- Random seed for initial M.
The default is 42.</p></li>
<li><p><strong>device</strong> (<em>string</em><em>, </em><em>optional</em>) -- Torch device to be used.
'cpu' to use PyTorch with CPU.
'gpu' to use cuda:0
The default is cpu.</p></li>
<li><p><strong>device_num</strong> (<em>string</em><em>, </em><em>optional</em>) -- Which device to to store the tensors.</p></li>
<li><p><strong>return_type</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type for the latent factors.
'torch' keep as torch tensors.
'numpy' convert to numpy arrays.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to be used in torch tensors.
Default is torch.cuda.DoubleTensor.</p></li>
<li><p><strong>follow_M</strong> (<em>bool</em><em>, </em><em>optional</em>) -- Saves M on each iteration.
The default is False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Minit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sptensor'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/CP_APR_Torch.html#CP_APR_MU.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Factorize the tensor X (i.e. compute the KRUSKAL tensor M).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>PyTorch Sparse Tensor</em><em> or </em><em>dense Numpy array as tensor</em>) -- <p>Original dense or sparse tensor X.</p>
<p>Can be used when Type = 'sptensor'. Then tensor parameter needs to be a PyTorch Sparse tensor.</p>
<p>Or use with Type = 'tensor' and pass the tensor parameter as a dense Numpy array.</p>
<p>Note that PyTorch only supports Type = 'sptensor'.</p>
</p></li>
<li><p><strong>coords</strong> (<em>Numpy array</em><em> (</em><em>i.e. array that is a list of list</em><em>)</em>) -- <p>Array of non-zero coordinates for sparse tensor X. COO format.</p>
<p>Each entry in this array is a coordinate of a non-zero value in the tensor.</p>
<p>Used when Type = 'sptensor' and tensor parameter is not passed.</p>
<p>len(Coords) is number of total entiries in X, and len(coords[0]) should give the number of dimensions.</p>
</p></li>
<li><p><strong>values</strong> (<em>Numpy array</em><em> (</em><em>i.e. list of non-zero values corresponding to each list of non-zero coordinates</em><em>)</em>) -- <p>Array of non-zero tensor entries. COO format.</p>
<p>Used when Type = 'sptensor' and tensor parameter is not passed.</p>
<p>Length of values must match the length of coords.</p>
</p></li>
<li><p><strong>rank</strong> (<em>int</em>) -- Tensor rank, i.e. number of components to extract.
The default is 2.</p></li>
<li><p><strong>Minit</strong> (<em>string</em><em> or </em><em>dictionary of latent factors</em>) -- <p>Initial value of latent factors.</p>
<p>If Minit = 'random', initial factors are chosen randomly from uniform distribution between 0 and 1.</p>
<p>Else, pass dictionary where the key is the mode number and value is array size d x r
where d is the number of elements on the dimension and r is the rank.</p>
<p>The default is &quot;random&quot;.</p>
</p></li>
<li><p><strong>Type</strong> (<em>string</em>) -- <p>Type of tensor (i.e. sparse or dense).</p>
<p>Use 'sptensor' for sparse, and 'tensor' for dense tensors.</p>
<p>'sptensor' can be used with method = 'torch', method = 'numpy'.</p>
<p>If 'sptensor' used, pass the list of non-zero coordinates using the Coords parameter
and the corresponding list of non-zero elements with values.</p>
<p>'sptensor' can also be used with the PyTorch Sparse format. Pass the torch.sparse format in the tensor parameter.</p>
<p>'tensor' can be used with method = 'numpy' only. Pass the tensor using tensor parameter in that case.</p>
<p>The default is 'sptensor'.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p><strong>result</strong> -- KRUSKAL tensor M is returned.
The latent factors can be found with the key 'Factors'.</p>
<p>The weight of each component can be found with the key 'Weights'.</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyCP_APR.torch_backend.ktensor_Torch">
<span id="pycp-apr-torch-backend-ktensor-torch-module"></span><h2>pyCP_APR.torch_backend.ktensor_Torch module<a class="headerlink" href="#module-pyCP_APR.torch_backend.ktensor_Torch" title="Permalink to this headline">¶</a></h2>
<p>ktensor_Torch.py contains the K_TENSOR class for KRUSKAL tensor M object representation.</p>
<p class="rubric">References</p>
<p>[1] General software, latest release: Brett W. Bader, Tamara G. Kolda and others, Tensor Toolbox for MATLAB, Version 3.2.1, www.tensortoolbox.org, April 5, 2021.</p>
<p>[2] Dense tensors: B. W. Bader and T. G. Kolda, Algorithm 862: MATLAB Tensor Classes for Fast Algorithm Prototyping, ACM Trans. Mathematical Software, 32(4):635-653, 2006, <a class="reference external" href="http://dx.doi.org/10.1145/1186785.1186794">http://dx.doi.org/10.1145/1186785.1186794</a>.</p>
<p>[3] Sparse, Kruskal, and Tucker tensors: B. W. Bader and T. G. Kolda, Efficient MATLAB Computations with Sparse and Factored Tensors, SIAM J. Scientific Computing, 30(1):205-231, 2007, <a class="reference external" href="http://dx.doi.org/10.1137/060676489">http://dx.doi.org/10.1137/060676489</a>.</p>
<p>[4] Chi, E.C. and Kolda, T.G., 2012. On tensors, sparsity, and nonnegative factorizations. SIAM Journal on Matrix Analysis and Applications, 33(4), pp.1272-1299.</p>
<p>&#64;author: Maksim Ekin Eren</p>
<dl class="py class">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyCP_APR.torch_backend.ktensor_Torch.</span></span><span class="sig-name descname"><span class="pre">K_TENSOR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Rank</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Minit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'torch.DoubleTensor'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/ktensor_Torch.html#K_TENSOR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Initilize the K_TENSOR class.</p>
<p>Creates the object representation of M.</p>
<p>If initial M is not passed, by default, creates M from uniform distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Rank</strong> (<em>int</em>) -- Tensor rank, i.e. number of components in M.</p></li>
<li><p><strong>Size</strong> (<em>list</em>) -- Shape of the tensor.</p></li>
<li><p><strong>Minit</strong> (<em>string</em><em> or </em><em>dictionary of latent factors</em>) -- <p>Initial value of latent factors.</p>
<p>If Minit = 'random', initial factors are chosen randomly from uniform distribution between 0 and 1.</p>
<p>Else, pass dictionary where the key is the mode number and value is array size d x r
where d is the number of elements on the dimension and r is the rank.</p>
<p>The default is &quot;random&quot;.</p>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>optional</em>) -- Random seed for initial M.
The default is 42.</p></li>
<li><p><strong>device</strong> (<em>string</em><em>, </em><em>optional</em>) -- Torch device to be used.
'cpu' to use PyTorch with CPU.
'gpu' to use cuda:0
The default is cpu.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to be used in torch tensors.
Default is torch.cuda.DoubleTensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR.deep_copy_factors">
<span class="sig-name descname"><span class="pre">deep_copy_factors</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/ktensor_Torch.html#K_TENSOR.deep_copy_factors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR.deep_copy_factors" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a deep copy of the latent factors in M.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>factors</strong> -- Copy of the latent factors of M.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyCP_APR.torch_backend.sptensor_Torch">
<span id="pycp-apr-torch-backend-sptensor-torch-module"></span><h2>pyCP_APR.torch_backend.sptensor_Torch module<a class="headerlink" href="#module-pyCP_APR.torch_backend.sptensor_Torch" title="Permalink to this headline">¶</a></h2>
<p>sptensor_Torch.py contains the SP_TENSOR class which is the object representation
of the sparse tensor X in COO format.</p>
<p class="rubric">References</p>
<p>[1] General software, latest release: Brett W. Bader, Tamara G. Kolda and others, Tensor Toolbox for MATLAB, Version 3.2.1, www.tensortoolbox.org, April 5, 2021.</p>
<p>[2] Dense tensors: B. W. Bader and T. G. Kolda, Algorithm 862: MATLAB Tensor Classes for Fast Algorithm Prototyping, ACM Trans. Mathematical Software, 32(4):635-653, 2006, <a class="reference external" href="http://dx.doi.org/10.1145/1186785.1186794">http://dx.doi.org/10.1145/1186785.1186794</a>.</p>
<p>[3] Sparse, Kruskal, and Tucker tensors: B. W. Bader and T. G. Kolda, Efficient MATLAB Computations with Sparse and Factored Tensors, SIAM J. Scientific Computing, 30(1):205-231, 2007, <a class="reference external" href="http://dx.doi.org/10.1137/060676489">http://dx.doi.org/10.1137/060676489</a>.</p>
<p>[4] Chi, E.C. and Kolda, T.G., 2012. On tensors, sparsity, and nonnegative factorizations. SIAM Journal on Matrix Analysis and Applications, 33(4), pp.1272-1299.</p>
<p>&#64;author: maksimekineren</p>
<dl class="py class">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.sptensor_Torch.SP_TENSOR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyCP_APR.torch_backend.sptensor_Torch.</span></span><span class="sig-name descname"><span class="pre">SP_TENSOR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Coords</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'torch.DoubleTensor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/sptensor_Torch.html#SP_TENSOR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.sptensor_Torch.SP_TENSOR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Initilize the SP_TENSOR class.</p>
<p>Sorts the tensor entries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Tensor</strong> (<em>PyTorch Sparse Tensor</em><em> or </em><em>dense Numpy array as tensor</em>) -- <p>Original dense or sparse tensor X.</p>
<p>Can be used when Type = 'sptensor'. Then Tensor needs to be a PyTorch Sparse tensor.</p>
<p>Or use with Type = 'tensor' and pass Tensor as a dense Numpy array.</p>
<p>Note that PyTorch only supports Type = 'sptensor'.</p>
</p></li>
<li><p><strong>Coords</strong> (<em>Numpy array</em><em> (</em><em>i.e. array that is a list of list</em><em>)</em>) -- <p>Array of non-zero coordinates for sparse tensor X. COO format.</p>
<p>Each entry in this array is a coordinate of a non-zero value in the tensor.</p>
<p>Used when Type = 'sptensor' and tensor parameter is not passed.</p>
<p>len(Coords) is number of total entiries in X, and len(coords[0]) should give the number of dimensions.</p>
</p></li>
<li><p><strong>Values</strong> (<em>Numpy array</em><em> (</em><em>i.e. list of non-zero values corresponding to each list of non-zero coordinates</em><em>)</em>) -- <p>Array of non-zero tensor entries. COO format.</p>
<p>Used when Type = 'sptensor' and tensor parameter is not passed.</p>
<p>Length of values must match the length of coords.</p>
</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to be used in torch tensors.
Default is torch.cuda.DoubleTensor.</p></li>
<li><p><strong>device</strong> (<em>string</em><em>, </em><em>optional</em>) -- Torch device to be used.
'cpu' to use PyTorch with CPU.
'gpu' to use cuda:0
The default is cpu.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-pyCP_APR.torch_backend">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pyCP_APR.torch_backend" title="Permalink to this headline">¶</a></h2>
<p>2021. Triad National Security, LLC. All rights reserved.
This program was produced under U.S. Government contract 89233218CNA000001 for Los Alamos
National Laboratory (LANL), which is operated by Triad National Security, LLC for the U.S.
Department of Energy/National Nuclear Security Administration. All rights in the program are
reserved by Triad National Security, LLC, and the U.S. Department of Energy/National Nuclear
Security Administration. The Government is granted for itself and others acting on its behalf a
nonexclusive, paid-up, irrevocable worldwide license in this material to reproduce, prepare
derivative works, distribute copies to the public, perform publicly and display publicly, and to permit
others to do so.</p>
</div>
</div>


              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="pyCP_APR.numpy_backend.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">pyCP_APR.numpy_backend package</p>
        </div>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Maksim E. Eren, Juston S. Moore, Erik Skau, Manish Bhattarai, Gopinath Chennupati, Boian S. Alexandrov<br/>
        
            &copy; Copyright 2021, LANL.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>