
<!DOCTYPE html>

<html lang="Python">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pyCP_APR.torch_cp.CP_APR_Torch &#8212; pyCP_APR 1.0.0 documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      <h1 class="site-logo" id="site-title">pyCP_APR 1.0.0 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../CP_APR.html">
   pyCP_APR.CP_APR API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../datasets.html">
   pyCP_APR.datasets API
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../modules.html">
   pyCP_APR Package
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../pyCP_APR.html">
     pyCP_APR package
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../pyCP_APR.applications.html">
       pyCP_APR.applications package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../pyCP_APR.numpy_cp.html">
       pyCP_APR.numpy_cp package
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../pyCP_APR.torch_cp.html">
       pyCP_APR.torch_cp package
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <h1>Source code for pyCP_APR.torch_cp.CP_APR_Torch</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Python implementation of the CP-APR algorithm [1-4] with PyTorch backend.\n</span>
<span class="sd">This backend can be used to factorize sparse tensorsin COO format on GPU or CPU.</span>

<span class="sd">References</span>
<span class="sd">========================================</span>
<span class="sd">[1] General software, latest release: Brett W. Bader, Tamara G. Kolda and others, Tensor Toolbox for MATLAB, Version 3.2.1, www.tensortoolbox.org, April 5, 2021.\n</span>
<span class="sd">[2] Dense tensors: B. W. Bader and T. G. Kolda, Algorithm 862: MATLAB Tensor Classes for Fast Algorithm Prototyping, ACM Trans. Mathematical Software, 32(4):635-653, 2006, http://dx.doi.org/10.1145/1186785.1186794.\n</span>
<span class="sd">[3] Sparse, Kruskal, and Tucker tensors: B. W. Bader and T. G. Kolda, Efficient MATLAB Computations with Sparse and Factored Tensors, SIAM J. Scientific Computing, 30(1):205-231, 2007, http://dx.doi.org/10.1137/060676489.\n</span>
<span class="sd">[4] Chi, E.C. and Kolda, T.G., 2012. On tensors, sparsity, and nonnegative factorizations. SIAM Journal on Matrix Analysis and Applications, 33(4), pp.1272-1299.</span>

<span class="sd">@author: Maksim Ekin Eren</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="kn">from</span> <span class="nn">cmath</span> <span class="kn">import</span> <span class="n">sqrt</span> <span class="k">as</span> <span class="n">sqrtc</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">tr</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="n">ktensor_Torch</span> <span class="kn">import</span> <span class="nn">K_TENSOR</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="n">sptensor_Torch</span> <span class="kn">import</span> <span class="nn">SP_TENSOR</span>


<div class="viewcode-block" id="CP_APR_MU"><a class="viewcode-back" href="../../../pyCP_APR.torch_cp.html#pyCP_APR.torch_cp.CP_APR_Torch.CP_APR_MU">[docs]</a><span class="k">class</span> <span class="nc">CP_APR_MU</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">kappa_tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">max_inner_iters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">n_iters</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">print_inner_itn</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">stoptime</span><span class="o">=</span><span class="mf">1e6</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span>
                 <span class="n">device_num</span><span class="o">=</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;numpy&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;torch.DoubleTensor&#39;</span><span class="p">,</span>
                 <span class="n">follow_M</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initilize the CP_APR_MU class. Sets up the class variables and the CUDA for</span>
<span class="sd">        tensors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        epsilon : float, optional</span>
<span class="sd">            Prevents zero division. Default is 1e-10.</span>
<span class="sd">        kappa : float, optional</span>
<span class="sd">            Fix slackness level. Default is 1e-2.</span>
<span class="sd">        kappa_tol : float, optional</span>
<span class="sd">            Tolerance on slackness level. Default is 1e-10.</span>
<span class="sd">        max_inner_iters : int, optional</span>
<span class="sd">            Number of inner iterations per epoch. Default is 10.</span>
<span class="sd">        n_iters : int, optional</span>
<span class="sd">            Number of iterations during optimization or epoch. Default is 1000.</span>
<span class="sd">        print_inner_itn : int, optional</span>
<span class="sd">            Print every *n* inner iterations. Does not print if 0. Default is 0.</span>
<span class="sd">        verbose : int, optional</span>
<span class="sd">            Print every n epoch, or ``n_iters``. Does not print if 0. Default is 10.</span>
<span class="sd">        stoptime : float, optional</span>
<span class="sd">            Number of seconds before early stopping. Default is 1e6.</span>
<span class="sd">        tol : float, optional</span>
<span class="sd">            KKT violations tolerance. Default is 1e-4.</span>
<span class="sd">        random_state : int, optional</span>
<span class="sd">            Random seed for initial M.</span>
<span class="sd">            The default is 42.</span>
<span class="sd">        device : string, optional</span>
<span class="sd">            Torch device to be used.</span>
<span class="sd">            &#39;cpu&#39; to use PyTorch with CPU.</span>
<span class="sd">            &#39;gpu&#39; to use cuda:0</span>
<span class="sd">            The default is cpu.</span>
<span class="sd">        device_num : string, optional</span>
<span class="sd">            Which device to to store the tensors.</span>
<span class="sd">        return_type : string, optional</span>
<span class="sd">            Type for the latent factors.</span>
<span class="sd">            &#39;torch&#39; keep as torch tensors.</span>
<span class="sd">            &#39;numpy&#39; convert to numpy arrays.</span>
<span class="sd">        dtype : string, optional</span>
<span class="sd">            Type to be used in torch tensors.</span>
<span class="sd">            Default is torch.cuda.DoubleTensor.</span>
<span class="sd">        follow_M : bool, optional</span>
<span class="sd">            Saves M on each iteration.</span>
<span class="sd">            The default is False.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Parameter for printing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print_inner_itn</span> <span class="o">=</span> <span class="n">print_inner_itn</span>

        <span class="c1"># Keep track of the runtime and the iteration stoptime</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_iter</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        
        <span class="c1"># Keep track of Ms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">follow_M</span> <span class="o">=</span> <span class="n">follow_M</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saved_Ms</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

        <span class="c1"># Set the default tensor type</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;gpu&#39;</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s1">&#39;torch.DoubleTensor&#39;</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="s1">&#39;torch.cuda.DoubleTensor&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="n">tr</span><span class="o">.</span><span class="n">set_default_tensor_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># GPU or CPU device parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_num</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">device_num</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;gpu&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tr</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_num</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Using&#39;</span><span class="p">,</span> <span class="n">tr</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_num</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;No CUDA device found&#39;</span><span class="p">)</span>

        <span class="c1"># Return Format</span>
        <span class="k">if</span> <span class="n">return_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;torch&#39;</span><span class="p">,</span> <span class="s1">&#39;numpy&#39;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_type</span> <span class="o">=</span> <span class="n">return_type</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;Invalid return type!&#39;</span><span class="p">)</span>

        <span class="c1"># Original X tensor, and KRUSKAL tensor M</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Optimization Parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stoptime</span> <span class="o">=</span> <span class="n">stoptime</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exec_time</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span> <span class="o">=</span> <span class="n">n_iters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iters</span> <span class="o">=</span> <span class="n">max_inner_iters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kappa</span> <span class="o">=</span> <span class="n">kappa</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kappa_tol</span> <span class="o">=</span> <span class="n">kappa_tol</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">kktViolations</span> <span class="o">=</span> <span class="o">-</span><span class="n">tr</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_iters</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nInnerIters</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_iters</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">times</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_iters</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logLikelihoods</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_iters</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">epsilon</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="mi">0</span>


<div class="viewcode-block" id="CP_APR_MU.train"><a class="viewcode-back" href="../../../pyCP_APR.torch_cp.html#pyCP_APR.torch_cp.CP_APR_Torch.CP_APR_MU.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="p">[],</span> <span class="n">coords</span><span class="o">=</span><span class="p">[],</span> <span class="n">values</span><span class="o">=</span><span class="p">[],</span> <span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">Minit</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">Type</span><span class="o">=</span><span class="s1">&#39;sptensor&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Factorize the tensor X (i.e. compute the KRUSKAL tensor M).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : PyTorch Sparse Tensor or dense Numpy array as tensor</span>
<span class="sd">            Original dense or sparse tensor X.\n</span>
<span class="sd">            Can be used when Type = &#39;sptensor&#39;. Then tensor parameter needs to be a PyTorch Sparse tensor.\n</span>
<span class="sd">            Or use with Type = &#39;tensor&#39; and pass the tensor parameter as a dense Numpy array.\n</span>
<span class="sd">            Note that PyTorch only supports Type = &#39;sptensor&#39;.</span>
<span class="sd">        coords : Numpy array (i.e. array that is a list of list)</span>
<span class="sd">            Array of non-zero coordinates for sparse tensor X. COO format.\n</span>
<span class="sd">            Each entry in this array is a coordinate of a non-zero value in the tensor.\n</span>
<span class="sd">            Used when Type = &#39;sptensor&#39; and tensor parameter is not passed.\n</span>
<span class="sd">            len(Coords) is number of total entiries in X, and len(coords[0]) should give the number of dimensions.</span>
<span class="sd">        values : Numpy array (i.e. list of non-zero values corresponding to each list of non-zero coordinates)</span>
<span class="sd">            Array of non-zero tensor entries. COO format.\n</span>
<span class="sd">            Used when Type = &#39;sptensor&#39; and tensor parameter is not passed.\n</span>
<span class="sd">            Length of values must match the length of coords.</span>
<span class="sd">        rank : int</span>
<span class="sd">            Tensor rank, i.e. number of components to extract.</span>
<span class="sd">            The default is 2.</span>
<span class="sd">        Minit : string or dictionary of latent factors</span>
<span class="sd">            Initial value of latent factors.\n</span>
<span class="sd">            If Minit = &#39;random&#39;, initial factors are chosen randomly from uniform distribution between 0 and 1.\n</span>
<span class="sd">            Else, pass dictionary where the key is the mode number and value is array size d x r</span>
<span class="sd">            where d is the number of elements on the dimension and r is the rank.\n</span>
<span class="sd">            The default is &quot;random&quot;.\n</span>
<span class="sd">        Type : string</span>
<span class="sd">            Type of tensor (i.e. sparse or dense).\n</span>
<span class="sd">            Use &#39;sptensor&#39; for sparse, and &#39;tensor&#39; for dense tensors.\n</span>
<span class="sd">            &#39;sptensor&#39; can be used with method = &#39;torch&#39;, method = &#39;numpy&#39;.\n</span>
<span class="sd">            If &#39;sptensor&#39; used, pass the list of non-zero coordinates using the Coords parameter</span>
<span class="sd">            and the corresponding list of non-zero elements with values.\n</span>
<span class="sd">            &#39;sptensor&#39; can also be used with the PyTorch Sparse format. Pass the torch.sparse format in the tensor parameter.\n</span>
<span class="sd">            &#39;tensor&#39; can be used with method = &#39;numpy&#39; only. Pass the tensor using tensor parameter in that case.\n</span>
<span class="sd">            The default is &#39;sptensor&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result : dict</span>
<span class="sd">            KRUSKAL tensor M is returned.</span>
<span class="sd">            The latent factors can be found with the key &#39;Factors&#39;.\n</span>
<span class="sd">            The weight of each component can be found with the key &#39;Weights&#39;.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;Number of components requested must be positive!&#39;</span><span class="p">)</span>

        <span class="c1"># Setup for iterations</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__setup</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">coords</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">Minit</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">Type</span><span class="p">)</span>

        <span class="n">Phi</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">kktModeViolations</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">Dimensions</span><span class="p">)</span>
        <span class="n">nViolations</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Iterate until convergence or early stop</span>
        <span class="k">for</span> <span class="n">outer_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span><span class="p">):</span>

            <span class="n">isConverged</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">Dimensions</span><span class="p">):</span>

                <span class="c1"># Adjust latent factors that are violating the slackness.</span>
                <span class="k">if</span> <span class="n">outer_iter</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">V</span> <span class="o">=</span> <span class="p">(</span><span class="n">Phi</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">kappa_tol</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">tr</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
                        <span class="n">nViolations</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)][</span><span class="n">V</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kappa</span>

                <span class="c1"># Absorb the component weight to dimension d</span>
                <span class="n">M</span><span class="o">.</span><span class="n">redistribute</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

                <span class="c1"># Product of all matrices but the d-th</span>
                <span class="n">Pi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__calculatePi</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>

                <span class="c1"># Multiplicative updates</span>
                <span class="k">for</span> <span class="n">inner_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iters</span><span class="p">):</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">nInnerIters</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="c1"># Matrix for multiplicative update</span>
                    <span class="n">Phi</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__calculatePhi</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">Pi</span><span class="p">)</span>

                    <span class="c1"># Check for convergence</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)],</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">Phi</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)])</span>
                    <span class="n">kktModeViolations</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__vectorizeForMu</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

                    <span class="k">if</span> <span class="n">kktModeViolations</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">:</span>
                        <span class="k">break</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">isConverged</span> <span class="o">=</span> <span class="kc">False</span>

                    <span class="c1"># Do the multiplicative update</span>
                    <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)],</span> <span class="n">Phi</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)])</span>

                    <span class="c1"># Print status</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">print_inner_itn</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">inner_iter</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">print_inner_itn</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mode = </span><span class="si">%d</span><span class="s2">, Inner Iter = </span><span class="si">%d</span><span class="s2">, KKT Violation = </span><span class="si">%.6f</span><span class="s2">&quot;</span> <span class="o">%</span> \
                              <span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">inner_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kktModeViolations</span><span class="p">[</span><span class="n">d</span><span class="p">]))</span>

                <span class="n">M</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">kktViolations</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">kktModeViolations</span><span class="p">)</span>

            <span class="c1"># calculate the log likelihood</span>
            <span class="n">M_</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">M</span><span class="p">),</span> <span class="n">N</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">obj_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tt_loglikelihood</span><span class="p">(</span><span class="n">M_</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logLikelihoods</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj_</span>
            
            <span class="c1"># if we want to save the results from current iteration</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">follow_M</span><span class="p">:</span>
                <span class="n">save_M</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_type</span> <span class="o">==</span> <span class="s1">&#39;numpy&#39;</span><span class="p">:</span>
                    <span class="n">save_M</span> <span class="o">=</span> <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__transfer_M_cpu</span><span class="p">(</span><span class="n">M_</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">save_M</span><span class="p">[</span><span class="s1">&#39;Factors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">M_</span><span class="o">.</span><span class="n">Factors</span>
                    <span class="n">save_M</span><span class="p">[</span><span class="s1">&#39;Weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">M_</span><span class="o">.</span><span class="n">Weights</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">saved_Ms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">save_M</span><span class="p">)</span>
            

            <span class="c1"># Print update</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">outer_iter</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iter=</span><span class="si">%d</span><span class="s2">, Inner Iter=</span><span class="si">%d</span><span class="s2">, KKT Violation=</span><span class="si">%.6f</span><span class="s2">, obj=</span><span class="si">%.6f</span><span class="s2">, nViolations=</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> \
                      <span class="p">(</span><span class="n">outer_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nInnerIters</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">kktViolations</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">],</span> \
                       <span class="bp">self</span><span class="o">.</span><span class="n">logLikelihoods</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">],</span> <span class="n">nViolations</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">]))</span>

            <span class="c1"># Check for convergence</span>
            <span class="k">if</span> <span class="n">isConverged</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exiting because all subproblems reached KKT tol.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoptime</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exiting because time limit exceeded.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="c1"># Done</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__finalize</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">outer_iter</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">__finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">outer_iter</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Helper functions to finalize the results. Calculates the final fit, performs the final</span>
<span class="sd">        tensor format conversions, shows the results if verbose, and returns the</span>
<span class="sd">        KRUSKAL tensor M.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        M : class</span>
<span class="sd">            KRUSKAL tensor M class. ktensor_Torch.K_TENSOR</span>
<span class="sd">        X : class</span>
<span class="sd">            Original tensor. sptensor_Torch.SP_TENSOR</span>
<span class="sd">        outer_iter : int</span>
<span class="sd">            Current epoch.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result : dict</span>
<span class="sd">            KRUSKAL tensor M is returned.</span>
<span class="sd">            The latent factors can be found with the key &#39;Factors&#39;.\n</span>
<span class="sd">            The weight of each component can be found with the key &#39;Weights&#39;.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Clean up final result</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tt_loglikelihood</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">M</span><span class="p">),</span> <span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_iter</span> <span class="o">=</span> <span class="n">outer_iter</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">result</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exec_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">normX</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">Values</span><span class="p">)</span>
            <span class="n">nrm_sqr</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="n">rem</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">innerprod</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="n">normresidual</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">normX</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">nrm_sqr</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">rem</span><span class="p">)</span>
            <span class="c1"># if negative in sqrt</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">normresidual</span> <span class="o">=</span> <span class="n">sqrtc</span><span class="p">(</span><span class="n">normX</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">nrm_sqr</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">rem</span><span class="p">)</span>

            <span class="n">fit</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">normresidual</span> <span class="o">/</span> <span class="n">normX</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===========================================&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Final log-likelihood = </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Final least squares fit = </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">fit</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Final KKT violation = </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">kktViolations</span><span class="p">[</span><span class="n">outer_iter</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Total inner iterations = </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">tr</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nInnerIters</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Total execution time = </span><span class="si">%.4f</span><span class="s2"> seconds&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">exec_time</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_type</span> <span class="o">==</span> <span class="s1">&#39;numpy&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Converting the latent factors to Numpy arrays.&quot;</span><span class="p">)</span>

            <span class="c1"># Convert KTENSOR to Numpy arrays</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__transfer_M_cpu</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>

            <span class="c1"># convert the optimization variables</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kktViolations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kktViolations</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nInnerIters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nInnerIters</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">times</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logLikelihoods</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logLikelihoods</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span> <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[</span><span class="s1">&#39;Factors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Factors</span>
            <span class="n">result</span><span class="p">[</span><span class="s1">&#39;Weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Weights</span>

        <span class="c1"># if GPU used, free up the space</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;torch&#39;</span><span class="p">:</span>
            <span class="n">tr</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

        <span class="c1"># Save the KRUSKAL tensor M and the original tensor X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">M</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">return</span> <span class="n">result</span>
    
    <span class="k">def</span> <span class="nf">__transfer_M_cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transfers M to CPU if requested.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        M : class</span>
<span class="sd">            KRUSKAL tensor M class. ktensor_Torch.K_TENSOR</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        M : dict</span>
<span class="sd">            M factors and weight that is transferred to CPU.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">M</span><span class="o">.</span><span class="n">Rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Dimensions</span><span class="p">):</span>
                <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
                <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">]</span>
                <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">)])</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Dimensions</span><span class="p">):</span>
                <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
                    
        <span class="n">result</span><span class="p">[</span><span class="s1">&#39;Factors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Factors</span>
        <span class="n">result</span><span class="p">[</span><span class="s1">&#39;Weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Weights</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">__setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Coords</span><span class="p">,</span> <span class="n">Values</span><span class="p">,</span> <span class="n">Minit</span><span class="p">,</span> <span class="n">Rank</span><span class="p">,</span> <span class="n">Type</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets up the classes for KRUSKAL tensor and the original tensor X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Tensor : PyTorch Sparse Tensor or dense Numpy array as tensor</span>
<span class="sd">            Original dense or sparse tensor X.\n</span>
<span class="sd">            Can be used when Type = &#39;sptensor&#39;. Then Tensor needs to be a PyTorch Sparse tensor.\n</span>
<span class="sd">            Or use with Type = &#39;tensor&#39; and pass Tensor as a dense Numpy array.\n</span>
<span class="sd">            Note that PyTorch only supports Type = &#39;sptensor&#39;.</span>
<span class="sd">        Coords : Numpy array (i.e. array that is a list of list)</span>
<span class="sd">            Array of non-zero coordinates for sparse tensor X. COO format.\n</span>
<span class="sd">            Each entry in this array is a coordinate of a non-zero value in the tensor.\n</span>
<span class="sd">            Used when Type = &#39;sptensor&#39; and tensor parameter is not passed.\n</span>
<span class="sd">            len(Coords) is number of total entiries in X, and len(coords[0]) should give the number of dimensions.</span>
<span class="sd">        Values : Numpy array (i.e. list of non-zero values corresponding to each list of non-zero coordinates)</span>
<span class="sd">            Array of non-zero tensor entries. COO format.\n</span>
<span class="sd">            Used when Type = &#39;sptensor&#39; and tensor parameter is not passed.\n</span>
<span class="sd">            Length of values must match the length of coords.</span>
<span class="sd">        Rank : int or list</span>
<span class="sd">            Tensor rank, or list of ranks for two tensors.\n</span>
<span class="sd">            List of ranks will allow using weighted prediction between the two latent factors.\n</span>
<span class="sd">            Pass a single integer or list of length two.\n</span>
<span class="sd">            The default is 2.</span>
<span class="sd">        Minit : string or dictionary of latent factors</span>
<span class="sd">            Initial value of latent factors.\n</span>
<span class="sd">            If Minit = &#39;random&#39;, initial factors are chosen randomly from uniform distribution between 0 and 1.\n</span>
<span class="sd">            Else, pass dictionary where the key is the mode number and value is array size d x r</span>
<span class="sd">            where d is the number of elements on the dimension and r is the rank.\n</span>
<span class="sd">            The default is &quot;random&quot;.\n</span>
<span class="sd">        Type : string</span>
<span class="sd">            Type of tensor (i.e. sparse or dense).\n</span>
<span class="sd">            Use &#39;sptensor&#39; for sparse, and &#39;tensor&#39; for dense tensors.\n</span>
<span class="sd">            &#39;sptensor&#39; can be used with method = &#39;torch&#39;, method = &#39;numpy&#39;.\n</span>
<span class="sd">            If &#39;sptensor&#39; used, pass the list of non-zero coordinates usingvCoords parameter</span>
<span class="sd">            and the corresponding list of non-zero elements with values.\n</span>
<span class="sd">            &#39;sptensor&#39; can also be used with the PyTorch Sparse format. Pass the torch.sparse format in the tensor parameter.\n</span>
<span class="sd">            &#39;tensor&#39; can be used with method = &#39;numpy&#39;. Pass the tensor using tensor parameter in that case.\n</span>
<span class="sd">            The default is &#39;sptensor&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        M : class</span>
<span class="sd">            KRUSKAL tensor M class. ktensor_Torch.K_TENSOR</span>
<span class="sd">        X : class</span>
<span class="sd">            Original tensor. sptensor_Torch.SP_TENSOR</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Setup the optimization variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kktViolations</span> <span class="o">=</span> <span class="o">-</span><span class="n">tr</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nInnerIters</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">times</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logLikelihoods</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Setup the tensors</span>
        <span class="k">if</span> <span class="n">Type</span> <span class="o">==</span> <span class="s1">&#39;sptensor&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tr</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">((</span><span class="n">Tensor</span><span class="o">.</span><span class="n">_values</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;Data tensor must be nonnegative for Poisson-based factorization.&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">_nnz</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;Non-zero values must be more than 0.&#39;</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Coords</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;Coordinates of the non-zero elements is not passed for sptensor.</span><span class="se">\</span>
<span class="s1">                             Use the Coords parameter.&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;Non-zero values are not passed for sptensor.</span><span class="se">\</span>
<span class="s1">                             Use the Values parameter&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">Coords</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;Data tensor must be nonnegative for Poisson-based factorization&#39;</span><span class="p">)</span>

            <span class="c1"># Convert the initial latent factors to pyTorch tensors</span>
            <span class="k">if</span> <span class="n">Minit</span> <span class="o">!=</span> <span class="s1">&#39;random&#39;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">Minit</span><span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Minit</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
                    <span class="n">Minit</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">Minit</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)])</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

            <span class="n">X</span> <span class="o">=</span> <span class="n">SP_TENSOR</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Coords</span><span class="p">,</span> <span class="n">Values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>


        <span class="k">elif</span> <span class="n">Type</span> <span class="o">==</span> <span class="s1">&#39;tensor&#39;</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s2">&quot;PyTorch backend only support sparse tensor implementation currently.&quot;</span><span class="p">)</span>

        <span class="n">M</span> <span class="o">=</span> <span class="n">K_TENSOR</span><span class="p">(</span><span class="n">Rank</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">Minit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">M</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CP-APR (MU):&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span>

    <span class="k">def</span> <span class="nf">__tt_loglikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function computes log-likelihood of tensor X with model M.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        M : class</span>
<span class="sd">            KRUSKAL tensor M class. ktensor_Torch.K_TENSOR</span>
<span class="sd">        X : class</span>
<span class="sd">            Original tensor. sptensor_Torch.SP_TENSOR</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        f : float</span>
<span class="sd">            log-likelihood.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">M</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">A</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="mi">0</span><span class="p">)][</span><span class="n">X</span><span class="o">.</span><span class="n">Coords</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">:]</span>

        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">Dimensions</span><span class="p">):</span>
            <span class="n">A</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)][</span><span class="n">X</span><span class="o">.</span><span class="n">Coords</span><span class="p">[:,</span> <span class="n">d</span><span class="p">],</span> <span class="p">:])</span>

        <span class="n">f</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">Values</span><span class="p">,</span> <span class="n">tr</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="mi">1</span><span class="p">))))</span> <span class="o">-</span> \
            <span class="n">tr</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">f</span>

    <span class="k">def</span> <span class="nf">__vectorizeForMu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Turn x into a vector.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array</span>
<span class="sd">            tensor x.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y : array</span>
<span class="sd">            flattenned x.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">__calculatePhi</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">Pi</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the matrix for MU</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        M : class</span>
<span class="sd">            KRUSKAL tensor M class. ktensor_Torch.K_TENSOR</span>
<span class="sd">        X : class</span>
<span class="sd">            Original tensor. sptensor_Torch.SP_TENSOR</span>
<span class="sd">        mode : int</span>
<span class="sd">            dimension.</span>
<span class="sd">        Pi : array</span>
<span class="sd">            Product of all matrices but nth.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Phi : array</span>
<span class="sd">            multiplicative update.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">Phi</span> <span class="o">=</span> <span class="o">-</span><span class="n">tr</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">Size</span><span class="p">[</span><span class="n">mode</span><span class="p">],</span> <span class="n">M</span><span class="o">.</span><span class="n">Rank</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">xsubs</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">Coords</span><span class="p">[:,</span> <span class="n">mode</span><span class="p">]</span>

        <span class="n">v</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">mode</span><span class="p">)][</span><span class="n">xsubs</span><span class="p">,</span> <span class="p">:],</span> <span class="n">Pi</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">wvals</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">Values</span><span class="p">,</span> <span class="n">tr</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Rank</span><span class="p">):</span>
            <span class="n">Yr</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">xsubs</span><span class="p">,</span> <span class="n">tr</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">wvals</span><span class="p">,</span> <span class="n">Pi</span><span class="p">[:,</span> <span class="n">r</span><span class="p">]),</span> <span class="n">X</span><span class="o">.</span><span class="n">Size</span><span class="p">[</span><span class="n">mode</span><span class="p">])</span>
            <span class="n">Phi</span><span class="p">[:,</span> <span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">Yr</span>

        <span class="k">return</span> <span class="n">Phi</span>

    <span class="k">def</span> <span class="nf">__calculatePi</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the product of all matrices without the &quot;mode&quot; dimension.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        M : class</span>
<span class="sd">            KRUSKAL tensor M class. ktensor_Torch.K_TENSOR</span>
<span class="sd">        X : class</span>
<span class="sd">            Original tensor. sptensor_Torch.SP_TENSOR</span>
<span class="sd">        mode : int</span>
<span class="sd">            dimension.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Pi : array</span>
<span class="sd">            product of all matrices but nth.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">Pi</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">nnz</span><span class="p">,</span> <span class="n">M</span><span class="o">.</span><span class="n">Rank</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">Dimensions</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">nn</span> <span class="o">!=</span> <span class="n">mode</span><span class="p">:</span>
                <span class="n">Pi</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">Factors</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">nn</span><span class="p">)][</span><span class="n">X</span><span class="o">.</span><span class="n">Coords</span><span class="p">[:,</span> <span class="n">nn</span><span class="p">],</span> <span class="p">:],</span> <span class="n">Pi</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Pi</span></div>
</pre></div>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Maksim E. Eren, Juston S. Moore, Erik Skau, Manish Bhattarai, Gopinath Chennupati, Boian S. Alexandrov<br/>
        
            &copy; Copyright 2021, LANL.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>